{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "492e7e5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve, auc, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define functions to read TSV files\n",
    "def read_tsv(filename, inf_ind, skip_1st=False, file_encoding=\"utf8\"):\n",
    "    extract_inf = []\n",
    "    with open(filename, \"r\", encoding=file_encoding) as tsv_f:\n",
    "        if skip_1st:\n",
    "            tsv_f.readline()\n",
    "        line = tsv_f.readline()\n",
    "        while line:\n",
    "            line_list = line.strip().split(\"\\t\")\n",
    "            temp_inf = [line_list[ind] for ind in inf_ind]\n",
    "            extract_inf.append(temp_inf)\n",
    "            line = tsv_f.readline()\n",
    "    return extract_inf\n",
    "\n",
    "# Define a function that reads an amino acid feature file and generates a feature dictionary\n",
    "def get_features(filename, f_num=15):\n",
    "    f_list = read_tsv(filename, list(range(16)), True)\n",
    "    f_dict = {}\n",
    "    left_num = 0\n",
    "    right_num = 0\n",
    "    if f_num > 15:\n",
    "        left_num = (f_num - 15) // 2\n",
    "        right_num = f_num - 15 - left_num\n",
    "    for f in f_list:\n",
    "        f_dict[f[0]] = [0] * left_num + [float(x) for x in f[1:]] + [0] * right_num\n",
    "    f_dict[\"X\"] = [0] * f_num\n",
    "    return f_dict\n",
    "\n",
    "# Defining Input Functions\n",
    "def generate_input(sps, sp_lbs, feature_dict, feature_num, ins_num, max_len):\n",
    "    xs, ys = [], []\n",
    "    i = 0\n",
    "    for sp in sps:\n",
    "        xs.append([[[0] * feature_num] * max_len] * ins_num)\n",
    "        ys.append(sp_lbs[i])\n",
    "        j = 0\n",
    "        for tcr in sp:\n",
    "            tcr_seq = tcr[0]\n",
    "            right_num = max_len - len(tcr_seq)\n",
    "            tcr_seq += \"X\" * right_num\n",
    "            tcr_matrix = []\n",
    "            for aa in tcr_seq:\n",
    "                tcr_matrix.append(feature_dict[aa.upper()])\n",
    "            xs[i][j] = tcr_matrix\n",
    "            j += 1\n",
    "        i += 1\n",
    "    xs = np.array(xs)\n",
    "    xs = xs.swapaxes(2, 3)\n",
    "    ys = np.array(ys)\n",
    "    return xs, ys\n",
    "\n",
    "\n",
    "#Define the Generate Label function\n",
    "def load_data(sample_dir):\n",
    "    training_data = []\n",
    "    training_labels = []\n",
    "    for sample_file in os.listdir(sample_dir):\n",
    "        training_data.append(read_tsv(os.path.join(sample_dir, sample_file), [0, 1], True))\n",
    "        if \"P\" in sample_file:\n",
    "            training_labels.append(1)\n",
    "        elif \"H\" in sample_file:\n",
    "            training_labels.append(0)\n",
    "        else:\n",
    "            print(\"Wrong sample filename! Please name positive samples with 'P' and negative samples with 'H'.\")\n",
    "            sys.exit(1)\n",
    "        \n",
    "    return training_data, training_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d623439",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the evaluation function\n",
    "def evaluate(model, criterion, test_loader, device=\"cuda\"):\n",
    "    test_total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for test_batch_x, test_batch_y in test_loader:\n",
    "            test_batch_x = test_batch_x.to(device)\n",
    "            test_batch_y = test_batch_y.to(device).view(-1, 1)  # 使标签的形状与模型输出匹配\n",
    "            test_pred = model(test_batch_x)\n",
    "\n",
    "            test_loss = criterion(test_pred, test_batch_y)\n",
    "            test_total_loss += test_loss.item()\n",
    "            all_preds.append(test_pred.cpu().numpy())\n",
    "            all_labels.append(test_batch_y.cpu().numpy())\n",
    "            \n",
    "        test_avg_loss = test_total_loss / len(test_loader)\n",
    "        return test_avg_loss, all_preds, all_labels\n",
    "    \n",
    "#Define the training function    \n",
    "from tqdm import tqdm\n",
    "def train(fold, model, criterion, optimizer, train_loader, valid_loader, epoches=100, device=\"cuda\"):\n",
    "    \n",
    "    \n",
    "    model_path = f'../model/{disease_name}checkpoint{fold}.pt'  # Save path of the model file\n",
    "    early_stopping = EarlyStopping(PATIENCE, path=model_path, verbose=False)\n",
    "    \n",
    "\n",
    "    epoch_train_losses = []\n",
    "    epoch_test_losses = []\n",
    "    with tqdm(total=epoches) as t:\n",
    "        t.set_description(f'{disease_name} - Fold {fold}')  \n",
    "        for epoch in range(epoches):\n",
    "            model.train()\n",
    "            total_loss = 0.0\n",
    "            for batch_x, batch_y in train_loader:\n",
    "                batch_x = batch_x.to(device)\n",
    "                batch_y = batch_y.to(device).view(-1, 1)  # 使标签的形状与模型输出匹配\n",
    "                pred = model(batch_x)\n",
    "\n",
    "                loss = criterion(pred, batch_y)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "            \n",
    "           \n",
    "            avg_loss = total_loss / len(train_loader)\n",
    "            epoch_train_losses.append(avg_loss)\n",
    "            test_avg_loss, _, _ = evaluate(model, criterion, test_loader, device)\n",
    "            epoch_test_losses.append(test_avg_loss) \n",
    "            t.set_postfix(loss=avg_loss, test_loss=test_avg_loss)\n",
    "            t.update(1)\n",
    "            early_stopping(test_avg_loss, model)\n",
    "            \n",
    "            if early_stopping.early_stop:\n",
    "                model.load_state_dict(torch.load(model_path))\n",
    "                #print('Early stopping')\n",
    "                break\n",
    "                \n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))     \n",
    "\n",
    "# Define a function to compute a binary classification indicator               \n",
    "def metrics(all_preds, all_labels, threshold=0.5):\n",
    "    \n",
    "    all_probs = sigmoid(np.array(all_preds))\n",
    "    binary_preds = (all_probs > threshold).astype(int)\n",
    "    conf_matrix = confusion_matrix(all_labels, binary_preds)\n",
    "    accuracy = accuracy_score(all_labels, binary_preds)\n",
    "    sensitivity = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    specificity = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    auc = roc_auc_score(all_labels, all_probs)\n",
    "    \n",
    "    return accuracy, sensitivity, specificity, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6e6f62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, pool_type, pool_size):\n",
    "        super(CNNLayer, self).__init__()\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.bn = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        if pool_type == 'max':\n",
    "            self.pool = nn.AdaptiveMaxPool1d(pool_size)\n",
    "        elif pool_type == 'avg':\n",
    "            self.pool = nn.AdaptiveAvgPool1d(pool_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.3, max_len=100):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        # 初始化 dropout 层\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # 生成位置索引并扩展维度以便后续计算\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        # 计算分母部分的值\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        # 初始化位置编码矩阵\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        # 计算位置编码的正弦部分\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        # 计算位置编码的余弦部分\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        # 注册为模型的缓冲区\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 将位置编码添加到输入中\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        # 应用 dropout 并返回结果\n",
    "        return self.dropout(x)\n",
    "       \n",
    "    \n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, feature_num, hidden_size, output_size, num_heads, num_layers, dropout, max_len, ins_num):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.ins_num = ins_num\n",
    "\n",
    "        self.input_embedding = nn.Linear(feature_num, hidden_size)\n",
    "        self.pos_encoder = PositionalEncoding(hidden_size, dropout, max_len)\n",
    "\n",
    "        # 添加第一个CNN层，使用平均池化\n",
    "        self.cnn1 = CNNLayer(hidden_size, hidden_size, kernel_size=8, stride=1, padding=4, pool_type='avg', pool_size=6)\n",
    "\n",
    "        self.batchnorm1 = nn.BatchNorm1d(hidden_size)  # 添加归一化层\n",
    "\n",
    "        self.encoder_layers = nn.TransformerEncoderLayer(d_model=hidden_size, nhead=num_heads, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layers, num_layers=num_layers)\n",
    "\n",
    "        # 添加第二个CNN层，使用最大池化\n",
    "        self.cnn2 = CNNLayer(hidden_size, hidden_size, kernel_size=8, stride=1, padding=4, pool_type='max', pool_size=1)\n",
    "        \n",
    "        self.batchnorm2 = nn.BatchNorm1d(hidden_size)  # 添加归一化层\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout)  # 添加Dropout层\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.input_embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = src.flatten(0, 1)\n",
    "        src = src.permute(2, 0, 1)\n",
    "        src = self.input_embedding(src)\n",
    "        src = self.pos_encoder(src)\n",
    "\n",
    "        # 通过第一个CNN层\n",
    "        src = src.permute(1, 2, 0)  # 调整维度以符合CNN输入\n",
    "        src = self.cnn1(src)\n",
    "        src = self.batchnorm1(src)  # 归一化\n",
    "        src = src.permute(2, 0, 1)  # 调整维度以回到Transformer输入格式\n",
    "\n",
    "        output = self.transformer_encoder(src)\n",
    "\n",
    "        # 通过第二个CNN层\n",
    "        output = output.permute(1, 2, 0)\n",
    "        output = self.cnn2(output)\n",
    "        output = self.batchnorm2(output)  # 归一化\n",
    "        output = output.permute(2, 0, 1)\n",
    "\n",
    "        output = output[0]\n",
    "        output = output.view(-1, self.ins_num, self.hidden_size)\n",
    "\n",
    "        # 应用Dropout\n",
    "        output = self.dropout(output)\n",
    "\n",
    "        output = output.mean(dim=1)\n",
    "        output = self.decoder(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "    \n",
    "def init_model():\n",
    "    # 设定模型参数\n",
    "    feature_num = 15  # 输入特征维度\n",
    "    hidden_size = 30  # 隐藏层大小\n",
    "    output_size = 1  # 输出大小\n",
    "    num_heads = 6  # 注意力头数\n",
    "    num_layers = 2  # Transformer编码器层数\n",
    "    dropout = 0.6  # Dropout比率\n",
    "    max_len = 24  # 序列最大长度\n",
    "    ins_num = 100  # 100个TCR序列\n",
    "\n",
    "    model = TransformerModel(feature_num, hidden_size, output_size, num_heads, num_layers, dropout, max_len, ins_num).to(device)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33636a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on RA dataset: 300 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "RA - Fold 0:  29%|▎| 582/2000 [00:12<00:31, 45.32it/s, loss=0.125, test_loss=0.6\n",
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "RA - Fold 1:  49%|▍| 979/2000 [00:21<00:22, 45.25it/s, loss=0.0375, test_loss=0.\n",
      "RA - Fold 2:  59%|▌| 1184/2000 [00:25<00:17, 46.44it/s, loss=0.0346, test_loss=0\n",
      "RA - Fold 3:  54%|▌| 1084/2000 [00:24<00:20, 44.39it/s, loss=0.037, test_loss=0.\n",
      "RA - Fold 4:  41%|▍| 814/2000 [00:17<00:26, 45.48it/s, loss=0.0651, test_loss=0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (RA): 0.9367\n",
      "Mean Sensitivity (RA): 0.9070\n",
      "Mean Specificity (RA): 0.9486\n",
      "Mean AUC (RA): 0.9788\n",
      "Working on T1D dataset: 461 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "T1D - Fold 0:  69%|▋| 1382/2000 [00:53<00:24, 25.69it/s, loss=0.0316, test_loss=\n",
      "T1D - Fold 1:  67%|▋| 1334/2000 [00:52<00:26, 25.23it/s, loss=0.0269, test_loss=\n",
      "T1D - Fold 2:  74%|▋| 1481/2000 [00:58<00:20, 25.48it/s, loss=0.0189, test_loss=\n",
      "T1D - Fold 3:  50%|▍| 990/2000 [00:38<00:39, 25.62it/s, loss=0.046, test_loss=0.\n",
      "T1D - Fold 4:  75%|▊| 1502/2000 [01:00<00:20, 24.82it/s, loss=0.0196, test_loss=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (T1D): 0.9501\n",
      "Mean Sensitivity (T1D): 0.9555\n",
      "Mean Specificity (T1D): 0.9439\n",
      "Mean AUC (T1D): 0.9907\n",
      "Working on MS dataset: 438 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "MS - Fold 0:  85%|▊| 1691/2000 [00:56<00:10, 29.84it/s, loss=0.00932, test_loss=\n",
      "MS - Fold 1:  56%|▌| 1118/2000 [00:38<00:30, 29.13it/s, loss=0.0255, test_loss=0\n",
      "MS - Fold 2: 100%|█| 2000/2000 [01:07<00:00, 29.77it/s, loss=0.00497, test_loss=\n",
      "MS - Fold 3:  91%|▉| 1821/2000 [01:02<00:06, 29.20it/s, loss=0.00614, test_loss=\n",
      "MS - Fold 4:  89%|▉| 1783/2000 [01:01<00:07, 29.10it/s, loss=0.0119, test_loss=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (MS): 0.9863\n",
      "Mean Sensitivity (MS): 0.9821\n",
      "Mean Specificity (MS): 0.9907\n",
      "Mean AUC (MS): 0.9996\n",
      "Working on IAA dataset: 279 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "IAA - Fold 0:  64%|▋| 1286/2000 [00:29<00:16, 43.20it/s, loss=0.0114, test_loss=\n",
      "IAA - Fold 1:  81%|▊| 1626/2000 [00:39<00:09, 40.83it/s, loss=0.00551, test_loss\n",
      "IAA - Fold 2:  93%|▉| 1860/2000 [00:44<00:03, 42.22it/s, loss=0.00625, test_loss\n",
      "IAA - Fold 3:  45%|▍| 899/2000 [00:21<00:26, 41.65it/s, loss=0.0246, test_loss=0\n",
      "IAA - Fold 4:  32%|▎| 649/2000 [00:14<00:30, 43.70it/s, loss=0.0781, test_loss=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (IAA): 0.9498\n",
      "Mean Sensitivity (IAA): 0.9385\n",
      "Mean Specificity (IAA): 0.9533\n",
      "Mean AUC (IAA): 0.9881\n",
      "Working on GBS dataset: 236 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "GBS - Fold 0:  19%|▏| 376/2000 [00:07<00:31, 51.26it/s, loss=0.15, test_loss=0.6\n",
      "GBS - Fold 1:  60%|▌| 1209/2000 [00:23<00:15, 51.07it/s, loss=0.00931, test_loss\n",
      "GBS - Fold 2:  18%|▏| 365/2000 [00:07<00:32, 49.77it/s, loss=0.145, test_loss=0.\n",
      "GBS - Fold 3:  16%|▏| 323/2000 [00:06<00:32, 51.70it/s, loss=0.201, test_loss=0.\n",
      "GBS - Fold 4:  42%|▍| 830/2000 [00:16<00:23, 49.50it/s, loss=0.0258, test_loss=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (GBS): 0.9195\n",
      "Mean Sensitivity (GBS): 0.5000\n",
      "Mean Specificity (GBS): 0.9626\n",
      "Mean AUC (GBS): 0.9359\n",
      "Working on JIA dataset: 302 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "JIA - Fold 0:  66%|▋| 1315/2000 [00:28<00:14, 45.67it/s, loss=0.0093, test_loss=\n",
      "JIA - Fold 1: 100%|█| 2000/2000 [00:44<00:00, 45.18it/s, loss=0.00384, test_loss\n",
      "JIA - Fold 2:  69%|▋| 1388/2000 [00:33<00:14, 41.62it/s, loss=0.00767, test_loss\n",
      "JIA - Fold 3:  89%|▉| 1786/2000 [00:43<00:05, 40.81it/s, loss=0.00373, test_loss\n",
      "JIA - Fold 4:  64%|▋| 1283/2000 [00:30<00:17, 41.76it/s, loss=0.00935, test_loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (JIA): 0.9934\n",
      "Mean Sensitivity (JIA): 0.9773\n",
      "Mean Specificity (JIA): 1.0000\n",
      "Mean AUC (JIA): 0.9986\n",
      "Working on Narcolepsy dataset: 263 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Narcolepsy - Fold 0:  21%|▏| 427/2000 [00:08<00:31, 49.44it/s, loss=0.106, test_\n",
      "Narcolepsy - Fold 1:  88%|▉| 1770/2000 [00:36<00:04, 49.09it/s, loss=0.00302, te\n",
      "Narcolepsy - Fold 2:  50%|▍| 992/2000 [00:20<00:20, 49.22it/s, loss=0.016, test_\n",
      "Narcolepsy - Fold 3:  71%|▋| 1421/2000 [00:29<00:11, 48.89it/s, loss=0.00674, te\n",
      "Narcolepsy - Fold 4: 100%|█| 2000/2000 [00:39<00:00, 50.02it/s, loss=0.00253, te\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (Narcolepsy): 0.9468\n",
      "Mean Sensitivity (Narcolepsy): 0.9388\n",
      "Mean Specificity (Narcolepsy): 0.9486\n",
      "Mean AUC (Narcolepsy): 0.9950\n",
      "Working on RA dataset: 300 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "RA - Fold 0:  38%|▍| 768/2000 [00:16<00:27, 45.51it/s, loss=0.0879, test_loss=0.\n",
      "RA - Fold 1:  61%|▌| 1217/2000 [00:26<00:17, 45.15it/s, loss=0.0293, test_loss=0\n",
      "RA - Fold 2:  57%|▌| 1136/2000 [00:24<00:18, 45.77it/s, loss=0.0271, test_loss=0\n",
      "RA - Fold 3:  85%|▊| 1701/2000 [00:36<00:06, 46.48it/s, loss=0.0135, test_loss=0\n",
      "RA - Fold 4:  41%|▍| 828/2000 [00:18<00:25, 45.22it/s, loss=0.0594, test_loss=0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (RA): 0.9467\n",
      "Mean Sensitivity (RA): 0.9070\n",
      "Mean Specificity (RA): 0.9626\n",
      "Mean AUC (RA): 0.9856\n",
      "Working on T1D dataset: 461 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "T1D - Fold 0:  45%|▍| 908/2000 [00:35<00:42, 25.60it/s, loss=0.0529, test_loss=0\n",
      "T1D - Fold 1:  71%|▋| 1412/2000 [00:55<00:22, 25.57it/s, loss=0.0274, test_loss=\n",
      "T1D - Fold 2:  94%|▉| 1874/2000 [01:12<00:04, 25.93it/s, loss=0.0157, test_loss=\n",
      "T1D - Fold 3:  41%|▍| 817/2000 [00:32<00:46, 25.53it/s, loss=0.066, test_loss=0.\n",
      "T1D - Fold 4:  30%|▎| 602/2000 [00:23<00:54, 25.57it/s, loss=0.126, test_loss=0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (T1D): 0.9414\n",
      "Mean Sensitivity (T1D): 0.9555\n",
      "Mean Specificity (T1D): 0.9252\n",
      "Mean AUC (T1D): 0.9875\n",
      "Working on MS dataset: 438 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "MS - Fold 0: 100%|█| 2000/2000 [01:06<00:00, 29.89it/s, loss=0.00474, test_loss=\n",
      "MS - Fold 1:  91%|▉| 1821/2000 [01:02<00:06, 28.92it/s, loss=0.00696, test_loss=\n",
      "MS - Fold 2:  74%|▋| 1479/2000 [00:51<00:18, 28.72it/s, loss=0.0147, test_loss=0\n",
      "MS - Fold 3:  42%|▍| 835/2000 [00:28<00:39, 29.14it/s, loss=0.0449, test_loss=0.\n",
      "MS - Fold 4:  91%|▉| 1817/2000 [01:02<00:06, 28.99it/s, loss=0.00638, test_loss=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (MS): 0.9840\n",
      "Mean Sensitivity (MS): 0.9955\n",
      "Mean Specificity (MS): 0.9720\n",
      "Mean AUC (MS): 0.9996\n",
      "Working on IAA dataset: 279 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "IAA - Fold 0: 100%|█| 2000/2000 [00:47<00:00, 42.09it/s, loss=0.00459, test_loss\n",
      "IAA - Fold 1:  63%|▋| 1264/2000 [00:30<00:17, 41.76it/s, loss=0.0128, test_loss=\n",
      "IAA - Fold 2:  61%|▌| 1212/2000 [00:29<00:18, 41.57it/s, loss=0.0114, test_loss=\n",
      "IAA - Fold 3:  62%|▌| 1242/2000 [00:29<00:18, 41.79it/s, loss=0.0249, test_loss=\n",
      "IAA - Fold 4:  62%|▌| 1236/2000 [00:29<00:18, 41.79it/s, loss=0.0122, test_loss=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (IAA): 0.9713\n",
      "Mean Sensitivity (IAA): 0.9231\n",
      "Mean Specificity (IAA): 0.9860\n",
      "Mean AUC (IAA): 0.9970\n",
      "Working on GBS dataset: 236 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "GBS - Fold 0:  18%|▏| 350/2000 [00:06<00:32, 50.66it/s, loss=0.163, test_loss=0.\n",
      "GBS - Fold 1: 100%|█| 2000/2000 [00:39<00:00, 50.09it/s, loss=0.0035, test_loss=\n",
      "GBS - Fold 2:  16%|▏| 330/2000 [00:06<00:32, 50.69it/s, loss=0.182, test_loss=1.\n",
      "GBS - Fold 3:  85%|▊| 1693/2000 [00:35<00:06, 47.23it/s, loss=0.00344, test_loss\n",
      "GBS - Fold 4:  57%|▌| 1148/2000 [00:24<00:17, 47.81it/s, loss=0.0143, test_loss=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (GBS): 0.9195\n",
      "Mean Sensitivity (GBS): 0.9091\n",
      "Mean Specificity (GBS): 0.9206\n",
      "Mean AUC (GBS): 0.9771\n",
      "Working on JIA dataset: 302 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "JIA - Fold 0: 100%|█| 2000/2000 [00:43<00:00, 45.81it/s, loss=0.0034, test_loss=\n",
      "JIA - Fold 1: 100%|█| 2000/2000 [00:43<00:00, 45.93it/s, loss=0.00435, test_loss\n",
      "JIA - Fold 2:  61%|▌| 1228/2000 [00:30<00:19, 40.18it/s, loss=0.0116, test_loss=\n",
      "JIA - Fold 3: 100%|█| 2000/2000 [00:49<00:00, 40.50it/s, loss=0.0044, test_loss=\n",
      "JIA - Fold 4:  55%|▌| 1093/2000 [00:26<00:22, 40.62it/s, loss=0.0147, test_loss=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (JIA): 0.9934\n",
      "Mean Sensitivity (JIA): 0.9773\n",
      "Mean Specificity (JIA): 1.0000\n",
      "Mean AUC (JIA): 0.9988\n",
      "Working on Narcolepsy dataset: 263 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Narcolepsy - Fold 0:  77%|▊| 1540/2000 [00:31<00:09, 49.57it/s, loss=0.0055, tes\n",
      "Narcolepsy - Fold 1:  15%|▏| 309/2000 [00:06<00:32, 51.37it/s, loss=0.19, test_l\n",
      "Narcolepsy - Fold 2:  91%|▉| 1813/2000 [00:35<00:03, 51.24it/s, loss=0.00337, te\n",
      "Narcolepsy - Fold 3:  74%|▋| 1482/2000 [00:29<00:10, 50.27it/s, loss=0.00485, te\n",
      "Narcolepsy - Fold 4: 100%|█| 2000/2000 [00:40<00:00, 49.87it/s, loss=0.00265, te\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (Narcolepsy): 0.9582\n",
      "Mean Sensitivity (Narcolepsy): 0.9592\n",
      "Mean Specificity (Narcolepsy): 0.9579\n",
      "Mean AUC (Narcolepsy): 0.9878\n",
      "Working on RA dataset: 300 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "RA - Fold 0:  67%|▋| 1337/2000 [00:28<00:14, 46.57it/s, loss=0.0256, test_loss=0\n",
      "RA - Fold 1:  35%|▎| 706/2000 [00:15<00:28, 45.79it/s, loss=0.086, test_loss=0.5\n",
      "RA - Fold 2:  33%|▎| 653/2000 [00:13<00:28, 46.72it/s, loss=0.0938, test_loss=0.\n",
      "RA - Fold 3:  88%|▉| 1761/2000 [00:36<00:05, 47.68it/s, loss=0.017, test_loss=0.\n",
      "RA - Fold 4:  76%|▊| 1527/2000 [00:32<00:10, 46.52it/s, loss=0.0176, test_loss=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (RA): 0.9100\n",
      "Mean Sensitivity (RA): 0.9302\n",
      "Mean Specificity (RA): 0.9019\n",
      "Mean AUC (RA): 0.9770\n",
      "Working on T1D dataset: 461 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "T1D - Fold 0:  61%|▌| 1225/2000 [00:47<00:29, 26.01it/s, loss=0.0307, test_loss=\n",
      "T1D - Fold 1:  96%|▉| 1917/2000 [01:14<00:03, 25.74it/s, loss=0.0102, test_loss=\n",
      "T1D - Fold 2:  82%|▊| 1649/2000 [01:03<00:13, 25.86it/s, loss=0.0273, test_loss=\n",
      "T1D - Fold 3:  59%|▌| 1173/2000 [00:44<00:31, 26.21it/s, loss=0.0377, test_loss=\n",
      "T1D - Fold 4:  65%|▋| 1300/2000 [00:50<00:26, 25.96it/s, loss=0.026, test_loss=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (T1D): 0.9436\n",
      "Mean Sensitivity (T1D): 0.9474\n",
      "Mean Specificity (T1D): 0.9393\n",
      "Mean AUC (T1D): 0.9900\n",
      "Working on MS dataset: 438 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "MS - Fold 0:  89%|▉| 1771/2000 [00:59<00:07, 29.70it/s, loss=0.0085, test_loss=0\n",
      "MS - Fold 1:  55%|▌| 1101/2000 [00:37<00:30, 29.16it/s, loss=0.0227, test_loss=0\n",
      "MS - Fold 2:  67%|▋| 1344/2000 [00:44<00:21, 30.07it/s, loss=0.0164, test_loss=0\n",
      "MS - Fold 3:  56%|▌| 1125/2000 [00:37<00:29, 30.04it/s, loss=0.0244, test_loss=0\n",
      "MS - Fold 4: 100%|█| 2000/2000 [01:06<00:00, 29.88it/s, loss=0.007, test_loss=0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (MS): 0.9817\n",
      "Mean Sensitivity (MS): 0.9955\n",
      "Mean Specificity (MS): 0.9673\n",
      "Mean AUC (MS): 0.9993\n",
      "Working on IAA dataset: 279 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "IAA - Fold 0:  87%|▊| 1743/2000 [00:40<00:05, 42.84it/s, loss=0.00651, test_loss\n",
      "IAA - Fold 1:  32%|▎| 636/2000 [00:14<00:32, 42.50it/s, loss=0.0678, test_loss=0\n",
      "IAA - Fold 2:  99%|▉| 1980/2000 [00:46<00:00, 42.26it/s, loss=0.00488, test_loss\n",
      "IAA - Fold 3:  64%|▋| 1282/2000 [00:29<00:16, 43.39it/s, loss=0.0113, test_loss=\n",
      "IAA - Fold 4:  52%|▌| 1046/2000 [00:24<00:22, 42.71it/s, loss=0.0235, test_loss=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (IAA): 0.9713\n",
      "Mean Sensitivity (IAA): 0.9077\n",
      "Mean Specificity (IAA): 0.9907\n",
      "Mean AUC (IAA): 0.9948\n",
      "Working on GBS dataset: 236 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "GBS - Fold 0:  17%|▏| 347/2000 [00:06<00:31, 52.26it/s, loss=0.175, test_loss=2.\n",
      "GBS - Fold 1: 100%|█| 2000/2000 [00:38<00:00, 51.92it/s, loss=0.0023, test_loss=\n",
      "GBS - Fold 2:  18%|▏| 364/2000 [00:07<00:31, 51.55it/s, loss=0.145, test_loss=0.\n",
      "GBS - Fold 3:  67%|▋| 1342/2000 [00:25<00:12, 52.02it/s, loss=0.00658, test_loss\n",
      "GBS - Fold 4:  30%|▎| 604/2000 [00:12<00:27, 49.92it/s, loss=0.0624, test_loss=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (GBS): 0.9364\n",
      "Mean Sensitivity (GBS): 0.8182\n",
      "Mean Specificity (GBS): 0.9486\n",
      "Mean AUC (GBS): 0.9686\n",
      "Working on JIA dataset: 302 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "JIA - Fold 0:  48%|▍| 959/2000 [00:20<00:22, 45.93it/s, loss=0.0191, test_loss=0\n",
      "JIA - Fold 1: 100%|█| 2000/2000 [00:41<00:00, 47.65it/s, loss=0.00448, test_loss\n",
      "JIA - Fold 2:  68%|▋| 1357/2000 [00:32<00:15, 41.53it/s, loss=0.00909, test_loss\n",
      "JIA - Fold 3:  93%|▉| 1864/2000 [00:44<00:03, 42.01it/s, loss=0.00522, test_loss\n",
      "JIA - Fold 4:  54%|▌| 1074/2000 [00:25<00:22, 41.81it/s, loss=0.0141, test_loss=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (JIA): 0.9834\n",
      "Mean Sensitivity (JIA): 0.9432\n",
      "Mean Specificity (JIA): 1.0000\n",
      "Mean AUC (JIA): 0.9988\n",
      "Working on Narcolepsy dataset: 263 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Narcolepsy - Fold 0: 100%|█| 2000/2000 [00:39<00:00, 51.15it/s, loss=0.00489, te\n",
      "Narcolepsy - Fold 1:  48%|▍| 958/2000 [00:18<00:20, 51.04it/s, loss=0.0163, test\n",
      "Narcolepsy - Fold 2:  58%|▌| 1160/2000 [00:22<00:16, 51.12it/s, loss=0.00862, te\n",
      "Narcolepsy - Fold 3:  17%|▏| 336/2000 [00:06<00:32, 51.44it/s, loss=0.148, test_\n",
      "Narcolepsy - Fold 4:  62%|▌| 1239/2000 [00:24<00:14, 51.56it/s, loss=0.00846, te\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (Narcolepsy): 0.9620\n",
      "Mean Sensitivity (Narcolepsy): 0.9388\n",
      "Mean Specificity (Narcolepsy): 0.9673\n",
      "Mean AUC (Narcolepsy): 0.9876\n",
      "Working on RA dataset: 300 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "RA - Fold 0:  31%|▎| 628/2000 [00:13<00:29, 46.66it/s, loss=0.11, test_loss=0.69\n",
      "RA - Fold 1: 100%|█| 2000/2000 [00:42<00:00, 47.52it/s, loss=0.0085, test_loss=0\n",
      "RA - Fold 2:  61%|▌| 1226/2000 [00:26<00:16, 47.04it/s, loss=0.0219, test_loss=0\n",
      "RA - Fold 3:  79%|▊| 1575/2000 [00:33<00:08, 47.43it/s, loss=0.0178, test_loss=0\n",
      "RA - Fold 4: 100%|█| 2000/2000 [00:42<00:00, 47.45it/s, loss=0.00699, test_loss=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (RA): 0.9367\n",
      "Mean Sensitivity (RA): 0.8721\n",
      "Mean Specificity (RA): 0.9626\n",
      "Mean AUC (RA): 0.9825\n",
      "Working on T1D dataset: 461 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "T1D - Fold 0: 100%|█| 2000/2000 [01:15<00:00, 26.57it/s, loss=0.0117, test_loss=\n",
      "T1D - Fold 1: 100%|█| 2000/2000 [01:15<00:00, 26.46it/s, loss=0.0122, test_loss=\n",
      "T1D - Fold 2:  72%|▋| 1444/2000 [00:57<00:21, 25.29it/s, loss=0.0229, test_loss=\n",
      "T1D - Fold 3:  59%|▌| 1184/2000 [00:45<00:31, 26.01it/s, loss=0.0352, test_loss=\n",
      "T1D - Fold 4:  77%|▊| 1537/2000 [01:00<00:18, 25.53it/s, loss=0.0192, test_loss=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (T1D): 0.9349\n",
      "Mean Sensitivity (T1D): 0.9676\n",
      "Mean Specificity (T1D): 0.8972\n",
      "Mean AUC (T1D): 0.9896\n",
      "Working on MS dataset: 438 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "MS - Fold 0:  94%|▉| 1884/2000 [01:01<00:03, 30.39it/s, loss=0.00773, test_loss=\n",
      "MS - Fold 1: 100%|█| 2000/2000 [01:06<00:00, 29.88it/s, loss=0.00632, test_loss=\n",
      "MS - Fold 2: 100%|█| 2000/2000 [01:06<00:00, 30.13it/s, loss=0.00801, test_loss=\n",
      "MS - Fold 3:  68%|▋| 1367/2000 [00:44<00:20, 30.41it/s, loss=0.0173, test_loss=0\n",
      "MS - Fold 4: 100%|█| 2000/2000 [01:06<00:00, 30.28it/s, loss=0.0066, test_loss=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (MS): 0.9977\n",
      "Mean Sensitivity (MS): 0.9955\n",
      "Mean Specificity (MS): 1.0000\n",
      "Mean AUC (MS): 1.0000\n",
      "Working on IAA dataset: 279 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "IAA - Fold 0:  97%|▉| 1934/2000 [00:44<00:01, 43.24it/s, loss=0.00912, test_loss\n",
      "IAA - Fold 1:  72%|▋| 1437/2000 [00:33<00:13, 43.28it/s, loss=0.0144, test_loss=\n",
      "IAA - Fold 2: 100%|█| 2000/2000 [00:46<00:00, 43.13it/s, loss=0.00872, test_loss\n",
      "IAA - Fold 3:  62%|▌| 1241/2000 [00:28<00:17, 43.06it/s, loss=0.0122, test_loss=\n",
      "IAA - Fold 4:  15%|▏| 301/2000 [00:06<00:37, 44.83it/s, loss=0.206, test_loss=1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (IAA): 0.9462\n",
      "Mean Sensitivity (IAA): 0.7692\n",
      "Mean Specificity (IAA): 1.0000\n",
      "Mean AUC (IAA): 0.9739\n",
      "Working on GBS dataset: 236 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "GBS - Fold 0:  18%|▏| 367/2000 [00:06<00:30, 53.31it/s, loss=0.15, test_loss=3.0\n",
      "GBS - Fold 1:  19%|▏| 384/2000 [00:07<00:31, 50.73it/s, loss=0.137, test_loss=0.\n",
      "GBS - Fold 2:  17%|▏| 339/2000 [00:06<00:32, 51.82it/s, loss=0.17, test_loss=0.6\n",
      "GBS - Fold 3:  17%|▏| 349/2000 [00:06<00:31, 51.92it/s, loss=0.178, test_loss=0.\n",
      "GBS - Fold 4:  36%|▎| 724/2000 [00:14<00:25, 50.85it/s, loss=0.0436, test_loss=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (GBS): 0.8729\n",
      "Mean Sensitivity (GBS): 0.6818\n",
      "Mean Specificity (GBS): 0.8925\n",
      "Mean AUC (GBS): 0.8857\n",
      "Working on JIA dataset: 302 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "JIA - Fold 0:  91%|▉| 1812/2000 [00:38<00:04, 46.88it/s, loss=0.00423, test_loss\n",
      "JIA - Fold 1:  86%|▊| 1725/2000 [00:37<00:05, 46.52it/s, loss=0.00476, test_loss\n",
      "JIA - Fold 2:  45%|▍| 893/2000 [00:21<00:26, 41.83it/s, loss=0.0219, test_loss=0\n",
      "JIA - Fold 3: 100%|█| 2000/2000 [00:47<00:00, 42.00it/s, loss=0.0027, test_loss=\n",
      "JIA - Fold 4:  37%|▎| 731/2000 [00:17<00:30, 41.69it/s, loss=0.0373, test_loss=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (JIA): 0.9901\n",
      "Mean Sensitivity (JIA): 0.9659\n",
      "Mean Specificity (JIA): 1.0000\n",
      "Mean AUC (JIA): 0.9980\n",
      "Working on Narcolepsy dataset: 263 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Narcolepsy - Fold 0:  24%|▏| 471/2000 [00:09<00:30, 50.95it/s, loss=0.0893, test\n",
      "Narcolepsy - Fold 1:  17%|▏| 331/2000 [00:06<00:32, 51.45it/s, loss=0.162, test_\n",
      "Narcolepsy - Fold 2:  88%|▉| 1754/2000 [00:34<00:04, 51.54it/s, loss=0.00399, te\n",
      "Narcolepsy - Fold 3:  96%|▉| 1928/2000 [00:37<00:01, 50.79it/s, loss=0.00304, te\n",
      "Narcolepsy - Fold 4: 100%|█| 2000/2000 [00:39<00:00, 51.06it/s, loss=0.00255, te\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (Narcolepsy): 0.9049\n",
      "Mean Sensitivity (Narcolepsy): 0.9592\n",
      "Mean Specificity (Narcolepsy): 0.8925\n",
      "Mean AUC (Narcolepsy): 0.9754\n",
      "Working on RA dataset: 300 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "RA - Fold 0:  70%|▋| 1410/2000 [00:30<00:12, 46.17it/s, loss=0.0203, test_loss=0\n",
      "RA - Fold 1:  31%|▎| 617/2000 [00:13<00:29, 46.30it/s, loss=0.106, test_loss=0.4\n",
      "RA - Fold 2:  28%|▎| 562/2000 [00:12<00:32, 44.52it/s, loss=0.149, test_loss=0.4\n",
      "RA - Fold 3:  61%|▌| 1218/2000 [00:26<00:16, 46.83it/s, loss=0.0304, test_loss=0\n",
      "RA - Fold 4:  33%|▎| 662/2000 [00:14<00:29, 44.80it/s, loss=0.101, test_loss=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (RA): 0.9133\n",
      "Mean Sensitivity (RA): 0.8721\n",
      "Mean Specificity (RA): 0.9299\n",
      "Mean AUC (RA): 0.9657\n",
      "Working on T1D dataset: 461 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "T1D - Fold 0:  84%|▊| 1677/2000 [01:04<00:12, 26.13it/s, loss=0.0141, test_loss=\n",
      "T1D - Fold 1:  23%|▏| 469/2000 [00:18<00:59, 25.88it/s, loss=0.192, test_loss=0.\n",
      "T1D - Fold 2:  44%|▍| 870/2000 [00:33<00:43, 26.13it/s, loss=0.0578, test_loss=0\n",
      "T1D - Fold 3:  77%|▊| 1541/2000 [01:01<00:18, 24.94it/s, loss=0.0235, test_loss=\n",
      "T1D - Fold 4:  51%|▌| 1022/2000 [00:39<00:37, 26.15it/s, loss=0.0482, test_loss=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (T1D): 0.8937\n",
      "Mean Sensitivity (T1D): 0.9231\n",
      "Mean Specificity (T1D): 0.8598\n",
      "Mean AUC (T1D): 0.9735\n",
      "Working on MS dataset: 438 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "MS - Fold 0:  86%|▊| 1722/2000 [00:58<00:09, 29.67it/s, loss=0.00813, test_loss=\n",
      "MS - Fold 1:  82%|▊| 1642/2000 [00:54<00:11, 30.12it/s, loss=0.00949, test_loss=\n",
      "MS - Fold 2:  80%|▊| 1604/2000 [00:53<00:13, 30.17it/s, loss=0.00749, test_loss=\n",
      "MS - Fold 3:  55%|▌| 1093/2000 [00:36<00:29, 30.28it/s, loss=0.023, test_loss=0.\n",
      "MS - Fold 4:  59%|▌| 1188/2000 [00:39<00:27, 29.82it/s, loss=0.0172, test_loss=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (MS): 0.9795\n",
      "Mean Sensitivity (MS): 0.9866\n",
      "Mean Specificity (MS): 0.9720\n",
      "Mean AUC (MS): 0.9989\n",
      "Working on IAA dataset: 279 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "IAA - Fold 0:  72%|▋| 1448/2000 [00:33<00:12, 43.76it/s, loss=0.0106, test_loss=\n",
      "IAA - Fold 1:  99%|▉| 1978/2000 [00:45<00:00, 43.75it/s, loss=0.00507, test_loss\n",
      "IAA - Fold 2:  48%|▍| 969/2000 [00:22<00:23, 43.14it/s, loss=0.0259, test_loss=0\n",
      "IAA - Fold 3:  27%|▎| 538/2000 [00:12<00:34, 41.87it/s, loss=0.0778, test_loss=0\n",
      "IAA - Fold 4: 100%|█| 2000/2000 [00:46<00:00, 43.22it/s, loss=0.00443, test_loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (IAA): 0.9713\n",
      "Mean Sensitivity (IAA): 0.9077\n",
      "Mean Specificity (IAA): 0.9907\n",
      "Mean AUC (IAA): 0.9953\n",
      "Working on GBS dataset: 236 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "GBS - Fold 0:  15%|▏| 303/2000 [00:05<00:31, 53.29it/s, loss=0.237, test_loss=2.\n",
      "GBS - Fold 1:  57%|▌| 1139/2000 [00:21<00:16, 52.20it/s, loss=0.0126, test_loss=\n",
      "GBS - Fold 2:  18%|▏| 363/2000 [00:06<00:31, 52.07it/s, loss=0.164, test_loss=0.\n",
      "GBS - Fold 3:  15%|▏| 301/2000 [00:05<00:32, 52.01it/s, loss=0.222, test_loss=2.\n",
      "GBS - Fold 4:  38%|▍| 769/2000 [00:15<00:24, 50.61it/s, loss=0.0302, test_loss=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (GBS): 0.9322\n",
      "Mean Sensitivity (GBS): 0.2727\n",
      "Mean Specificity (GBS): 1.0000\n",
      "Mean AUC (GBS): 0.8154\n",
      "Working on JIA dataset: 302 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "JIA - Fold 0: 100%|█| 2000/2000 [00:42<00:00, 46.98it/s, loss=0.00304, test_loss\n",
      "JIA - Fold 1: 100%|█| 2000/2000 [00:41<00:00, 47.87it/s, loss=0.00555, test_loss\n",
      "JIA - Fold 2:  52%|▌| 1037/2000 [00:24<00:22, 41.93it/s, loss=0.0179, test_loss=\n",
      "JIA - Fold 3: 100%|█| 2000/2000 [00:47<00:00, 42.23it/s, loss=0.00491, test_loss\n",
      "JIA - Fold 4:  88%|▉| 1766/2000 [00:40<00:05, 43.12it/s, loss=0.00363, test_loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (JIA): 0.9901\n",
      "Mean Sensitivity (JIA): 0.9773\n",
      "Mean Specificity (JIA): 0.9953\n",
      "Mean AUC (JIA): 0.9986\n",
      "Working on Narcolepsy dataset: 263 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Narcolepsy - Fold 0:  68%|▋| 1362/2000 [00:26<00:12, 51.68it/s, loss=0.00649, te\n",
      "Narcolepsy - Fold 1:  46%|▍| 913/2000 [00:17<00:20, 52.05it/s, loss=0.0212, test\n",
      "Narcolepsy - Fold 2:  38%|▍| 759/2000 [00:14<00:24, 50.90it/s, loss=0.0292, test\n",
      "Narcolepsy - Fold 3:  64%|▋| 1271/2000 [00:24<00:14, 50.98it/s, loss=0.00952, te\n",
      "Narcolepsy - Fold 4:  20%|▏| 392/2000 [00:07<00:31, 50.33it/s, loss=0.112, test_\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (Narcolepsy): 0.9392\n",
      "Mean Sensitivity (Narcolepsy): 0.9796\n",
      "Mean Specificity (Narcolepsy): 0.9299\n",
      "Mean AUC (Narcolepsy): 0.9842\n",
      "Working on RA dataset: 300 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "RA - Fold 0:  29%|▎| 585/2000 [00:12<00:30, 47.09it/s, loss=0.122, test_loss=0.8\n",
      "RA - Fold 1:  53%|▌| 1060/2000 [00:22<00:20, 46.99it/s, loss=0.046, test_loss=0.\n",
      "RA - Fold 2:  58%|▌| 1153/2000 [00:24<00:17, 47.12it/s, loss=0.0299, test_loss=0\n",
      "RA - Fold 3:  46%|▍| 930/2000 [00:19<00:22, 47.22it/s, loss=0.0617, test_loss=0.\n",
      "RA - Fold 4:  38%|▍| 760/2000 [00:16<00:26, 46.03it/s, loss=0.0832, test_loss=0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (RA): 0.8967\n",
      "Mean Sensitivity (RA): 0.8837\n",
      "Mean Specificity (RA): 0.9019\n",
      "Mean AUC (RA): 0.9701\n",
      "Working on T1D dataset: 461 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "T1D - Fold 0: 100%|█| 2000/2000 [01:16<00:00, 26.17it/s, loss=0.00682, test_loss\n",
      "T1D - Fold 1: 100%|█| 2000/2000 [01:15<00:00, 26.55it/s, loss=0.0109, test_loss=\n",
      "T1D - Fold 2:  76%|▊| 1530/2000 [00:57<00:17, 26.48it/s, loss=0.0222, test_loss=\n",
      "T1D - Fold 3:  50%|▌| 1005/2000 [00:38<00:38, 26.17it/s, loss=0.0512, test_loss=\n",
      "T1D - Fold 4:  87%|▊| 1735/2000 [01:06<00:10, 26.26it/s, loss=0.0165, test_loss=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (T1D): 0.9458\n",
      "Mean Sensitivity (T1D): 0.9555\n",
      "Mean Specificity (T1D): 0.9346\n",
      "Mean AUC (T1D): 0.9900\n",
      "Working on MS dataset: 438 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "MS - Fold 0: 100%|█| 2000/2000 [01:06<00:00, 30.22it/s, loss=0.00597, test_loss=\n",
      "MS - Fold 1: 100%|█| 2000/2000 [01:05<00:00, 30.49it/s, loss=0.00608, test_loss=\n",
      "MS - Fold 2: 100%|▉| 1990/2000 [01:05<00:00, 30.30it/s, loss=0.00393, test_loss=\n",
      "MS - Fold 3:  86%|▊| 1710/2000 [00:55<00:09, 30.62it/s, loss=0.00805, test_loss=\n",
      "MS - Fold 4: 100%|█| 2000/2000 [01:06<00:00, 30.19it/s, loss=0.00538, test_loss=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (MS): 0.9909\n",
      "Mean Sensitivity (MS): 0.9955\n",
      "Mean Specificity (MS): 0.9860\n",
      "Mean AUC (MS): 0.9995\n",
      "Working on IAA dataset: 279 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "IAA - Fold 0:  85%|▊| 1693/2000 [00:38<00:07, 43.73it/s, loss=0.0059, test_loss=\n",
      "IAA - Fold 1: 100%|█| 2000/2000 [00:46<00:00, 43.20it/s, loss=0.00539, test_loss\n",
      "IAA - Fold 2:  93%|▉| 1859/2000 [00:42<00:03, 43.96it/s, loss=0.00314, test_loss\n",
      "IAA - Fold 3:  30%|▎| 591/2000 [00:14<00:33, 41.70it/s, loss=0.0759, test_loss=0\n",
      "IAA - Fold 4:  36%|▎| 721/2000 [00:16<00:29, 43.27it/s, loss=0.0542, test_loss=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (IAA): 0.9677\n",
      "Mean Sensitivity (IAA): 0.9385\n",
      "Mean Specificity (IAA): 0.9766\n",
      "Mean AUC (IAA): 0.9952\n",
      "Working on GBS dataset: 236 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "GBS - Fold 0:  15%|▏| 308/2000 [00:05<00:31, 53.29it/s, loss=0.22, test_loss=2.1\n",
      "GBS - Fold 1:  40%|▍| 798/2000 [00:15<00:22, 52.47it/s, loss=0.0306, test_loss=0\n",
      "GBS - Fold 2:  67%|▋| 1332/2000 [00:26<00:13, 50.73it/s, loss=0.00767, test_loss\n",
      "GBS - Fold 3:  15%|▏| 303/2000 [00:05<00:31, 53.35it/s, loss=0.223, test_loss=2.\n",
      "GBS - Fold 4:  38%|▍| 764/2000 [00:14<00:24, 51.13it/s, loss=0.0301, test_loss=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (GBS): 0.8136\n",
      "Mean Sensitivity (GBS): 0.7727\n",
      "Mean Specificity (GBS): 0.8178\n",
      "Mean AUC (GBS): 0.9140\n",
      "Working on JIA dataset: 302 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "JIA - Fold 0:  58%|▌| 1169/2000 [00:25<00:18, 46.14it/s, loss=0.0123, test_loss=\n",
      "JIA - Fold 1:  82%|▊| 1636/2000 [00:34<00:07, 47.95it/s, loss=0.00678, test_loss\n",
      "JIA - Fold 2:  55%|▌| 1109/2000 [00:26<00:21, 42.07it/s, loss=0.0145, test_loss=\n",
      "JIA - Fold 3: 100%|█| 2000/2000 [00:47<00:00, 42.09it/s, loss=0.00373, test_loss\n",
      "JIA - Fold 4: 100%|█| 2000/2000 [00:46<00:00, 42.90it/s, loss=0.00405, test_loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (JIA): 0.9934\n",
      "Mean Sensitivity (JIA): 0.9773\n",
      "Mean Specificity (JIA): 1.0000\n",
      "Mean AUC (JIA): 0.9986\n",
      "Working on Narcolepsy dataset: 263 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Narcolepsy - Fold 0:  17%|▏| 338/2000 [00:06<00:32, 51.42it/s, loss=0.157, test_\n",
      "Narcolepsy - Fold 1: 100%|█| 2000/2000 [00:39<00:00, 50.77it/s, loss=0.00318, te\n",
      "Narcolepsy - Fold 2:  61%|▌| 1228/2000 [00:23<00:14, 51.47it/s, loss=0.0146, tes\n",
      "Narcolepsy - Fold 3:  86%|▊| 1727/2000 [00:34<00:05, 49.35it/s, loss=0.00533, te\n",
      "Narcolepsy - Fold 4:  20%|▏| 402/2000 [00:07<00:31, 51.04it/s, loss=0.114, test_\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (Narcolepsy): 0.9163\n",
      "Mean Sensitivity (Narcolepsy): 0.9796\n",
      "Mean Specificity (Narcolepsy): 0.9019\n",
      "Mean AUC (Narcolepsy): 0.9884\n",
      "Working on RA dataset: 300 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "RA - Fold 0:  42%|▍| 836/2000 [00:18<00:25, 45.86it/s, loss=0.0532, test_loss=0.\n",
      "RA - Fold 1:  39%|▍| 783/2000 [00:16<00:26, 46.30it/s, loss=0.0683, test_loss=0.\n",
      "RA - Fold 2: 100%|▉| 1990/2000 [00:41<00:00, 47.45it/s, loss=0.0087, test_loss=0\n",
      "RA - Fold 3:  58%|▌| 1154/2000 [00:24<00:17, 47.24it/s, loss=0.0235, test_loss=0\n",
      "RA - Fold 4:  51%|▌| 1022/2000 [00:21<00:20, 47.23it/s, loss=0.0345, test_loss=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (RA): 0.9133\n",
      "Mean Sensitivity (RA): 0.8837\n",
      "Mean Specificity (RA): 0.9252\n",
      "Mean AUC (RA): 0.9772\n",
      "Working on T1D dataset: 461 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "T1D - Fold 0:  77%|▊| 1548/2000 [00:58<00:16, 26.67it/s, loss=0.0243, test_loss=\n",
      "T1D - Fold 1:  63%|▋| 1251/2000 [00:48<00:29, 25.59it/s, loss=0.0397, test_loss=\n",
      "T1D - Fold 2:  55%|▌| 1109/2000 [00:42<00:33, 26.28it/s, loss=0.0394, test_loss=\n",
      "T1D - Fold 3:  48%|▍| 970/2000 [00:37<00:40, 25.63it/s, loss=0.0507, test_loss=0\n",
      "T1D - Fold 4:  54%|▌| 1081/2000 [00:42<00:35, 25.66it/s, loss=0.0412, test_loss=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (T1D): 0.9436\n",
      "Mean Sensitivity (T1D): 0.9717\n",
      "Mean Specificity (T1D): 0.9112\n",
      "Mean AUC (T1D): 0.9877\n",
      "Working on MS dataset: 438 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "MS - Fold 0:  76%|▊| 1515/2000 [00:49<00:15, 30.32it/s, loss=0.0106, test_loss=0\n",
      "MS - Fold 1: 100%|█| 2000/2000 [01:05<00:00, 30.41it/s, loss=0.00528, test_loss=\n",
      "MS - Fold 2: 100%|█| 2000/2000 [01:06<00:00, 30.08it/s, loss=0.0049, test_loss=0\n",
      "MS - Fold 3:  60%|▌| 1198/2000 [00:39<00:26, 30.27it/s, loss=0.0234, test_loss=0\n",
      "MS - Fold 4: 100%|█| 2000/2000 [01:06<00:00, 29.95it/s, loss=0.00642, test_loss=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (MS): 0.9817\n",
      "Mean Sensitivity (MS): 0.9821\n",
      "Mean Specificity (MS): 0.9813\n",
      "Mean AUC (MS): 0.9995\n",
      "Working on IAA dataset: 279 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "IAA - Fold 0:  62%|▌| 1235/2000 [00:28<00:17, 42.88it/s, loss=0.018, test_loss=0\n",
      "IAA - Fold 1:  98%|▉| 1969/2000 [00:44<00:00, 44.06it/s, loss=0.00541, test_loss\n",
      "IAA - Fold 2:  95%|▉| 1905/2000 [00:43<00:02, 43.91it/s, loss=0.00537, test_loss\n",
      "IAA - Fold 3:  30%|▎| 593/2000 [00:13<00:33, 42.51it/s, loss=0.0631, test_loss=0\n",
      "IAA - Fold 4:  49%|▍| 975/2000 [00:22<00:23, 43.38it/s, loss=0.0174, test_loss=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (IAA): 0.9462\n",
      "Mean Sensitivity (IAA): 0.8769\n",
      "Mean Specificity (IAA): 0.9673\n",
      "Mean AUC (IAA): 0.9879\n",
      "Working on GBS dataset: 236 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "GBS - Fold 0:  19%|▏| 380/2000 [00:07<00:31, 51.25it/s, loss=0.133, test_loss=1.\n",
      "GBS - Fold 1:  56%|▌| 1120/2000 [00:21<00:16, 52.10it/s, loss=0.0113, test_loss=\n",
      "GBS - Fold 2:  16%|▏| 312/2000 [00:05<00:32, 52.50it/s, loss=0.2, test_loss=1.04\n",
      "GBS - Fold 3:  66%|▋| 1316/2000 [00:25<00:13, 51.09it/s, loss=0.0101, test_loss=\n",
      "GBS - Fold 4:  64%|▋| 1289/2000 [00:25<00:13, 51.05it/s, loss=0.00675, test_loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (GBS): 0.9280\n",
      "Mean Sensitivity (GBS): 0.8636\n",
      "Mean Specificity (GBS): 0.9346\n",
      "Mean AUC (GBS): 0.9528\n",
      "Working on JIA dataset: 302 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "JIA - Fold 0:  85%|▊| 1696/2000 [00:36<00:06, 46.45it/s, loss=0.0058, test_loss=\n",
      "JIA - Fold 1: 100%|█| 2000/2000 [00:42<00:00, 47.16it/s, loss=0.00409, test_loss\n",
      "JIA - Fold 2:  66%|▋| 1323/2000 [00:31<00:15, 42.44it/s, loss=0.0114, test_loss=\n",
      "JIA - Fold 3: 100%|█| 2000/2000 [00:46<00:00, 42.76it/s, loss=0.00516, test_loss\n",
      "JIA - Fold 4:  71%|▋| 1427/2000 [00:34<00:13, 41.51it/s, loss=0.00683, test_loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (JIA): 0.9868\n",
      "Mean Sensitivity (JIA): 0.9545\n",
      "Mean Specificity (JIA): 1.0000\n",
      "Mean AUC (JIA): 0.9986\n",
      "Working on Narcolepsy dataset: 263 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Narcolepsy - Fold 0:  15%|▏| 307/2000 [00:05<00:32, 51.77it/s, loss=0.182, test_\n",
      "Narcolepsy - Fold 1:  63%|▋| 1266/2000 [00:24<00:14, 51.82it/s, loss=0.00934, te\n",
      "Narcolepsy - Fold 2:  87%|▊| 1739/2000 [00:33<00:05, 51.58it/s, loss=0.0043, tes\n",
      "Narcolepsy - Fold 3: 100%|█| 2000/2000 [00:38<00:00, 51.52it/s, loss=0.00245, te\n",
      "Narcolepsy - Fold 4:  16%|▏| 316/2000 [00:06<00:32, 52.39it/s, loss=0.167, test_\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (Narcolepsy): 0.7871\n",
      "Mean Sensitivity (Narcolepsy): 0.7959\n",
      "Mean Specificity (Narcolepsy): 0.7850\n",
      "Mean AUC (Narcolepsy): 0.9309\n",
      "Working on RA dataset: 300 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "RA - Fold 0:  52%|▌| 1050/2000 [00:22<00:20, 46.88it/s, loss=0.0437, test_loss=0\n",
      "RA - Fold 1:  46%|▍| 912/2000 [00:19<00:22, 47.71it/s, loss=0.0557, test_loss=0.\n",
      "RA - Fold 2:  45%|▍| 892/2000 [00:19<00:23, 46.81it/s, loss=0.0481, test_loss=0.\n",
      "RA - Fold 3:  72%|▋| 1433/2000 [00:30<00:12, 46.90it/s, loss=0.0189, test_loss=0\n",
      "RA - Fold 4:  68%|▋| 1353/2000 [00:28<00:13, 47.83it/s, loss=0.022, test_loss=0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (RA): 0.9200\n",
      "Mean Sensitivity (RA): 0.8953\n",
      "Mean Specificity (RA): 0.9299\n",
      "Mean AUC (RA): 0.9770\n",
      "Working on T1D dataset: 461 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "T1D - Fold 0: 100%|█| 2000/2000 [01:15<00:00, 26.59it/s, loss=0.00861, test_loss\n",
      "T1D - Fold 1: 100%|█| 2000/2000 [01:14<00:00, 26.71it/s, loss=0.0118, test_loss=\n",
      "T1D - Fold 2:  67%|▋| 1342/2000 [00:50<00:24, 26.40it/s, loss=0.0278, test_loss=\n",
      "T1D - Fold 3:  67%|▋| 1344/2000 [00:51<00:25, 26.05it/s, loss=0.0233, test_loss=\n",
      "T1D - Fold 4:  50%|▌| 1007/2000 [00:38<00:38, 26.06it/s, loss=0.0525, test_loss=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (T1D): 0.9523\n",
      "Mean Sensitivity (T1D): 0.9757\n",
      "Mean Specificity (T1D): 0.9252\n",
      "Mean AUC (T1D): 0.9888\n",
      "Working on MS dataset: 438 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "MS - Fold 0: 100%|█| 2000/2000 [01:05<00:00, 30.38it/s, loss=0.00863, test_loss=\n",
      "MS - Fold 1: 100%|█| 2000/2000 [01:06<00:00, 30.18it/s, loss=0.00697, test_loss=\n",
      "MS - Fold 2: 100%|█| 2000/2000 [01:05<00:00, 30.58it/s, loss=0.00452, test_loss=\n",
      "MS - Fold 3:  96%|▉| 1929/2000 [01:03<00:02, 30.33it/s, loss=0.00529, test_loss=\n",
      "MS - Fold 4:  92%|▉| 1837/2000 [01:00<00:05, 30.57it/s, loss=0.00736, test_loss=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (MS): 0.9863\n",
      "Mean Sensitivity (MS): 0.9955\n",
      "Mean Specificity (MS): 0.9766\n",
      "Mean AUC (MS): 0.9994\n",
      "Working on IAA dataset: 279 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "IAA - Fold 0:  59%|▌| 1184/2000 [00:27<00:18, 43.69it/s, loss=0.0238, test_loss=\n",
      "IAA - Fold 1:  89%|▉| 1771/2000 [00:39<00:05, 44.39it/s, loss=0.00759, test_loss\n",
      "IAA - Fold 2:  71%|▋| 1428/2000 [00:32<00:12, 44.07it/s, loss=0.00973, test_loss\n",
      "IAA - Fold 3:  38%|▍| 768/2000 [00:18<00:28, 42.59it/s, loss=0.0471, test_loss=0\n",
      "IAA - Fold 4: 100%|█| 2000/2000 [00:46<00:00, 43.38it/s, loss=0.00485, test_loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (IAA): 0.9713\n",
      "Mean Sensitivity (IAA): 0.9538\n",
      "Mean Specificity (IAA): 0.9766\n",
      "Mean AUC (IAA): 0.9965\n",
      "Working on GBS dataset: 236 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "GBS - Fold 0:  17%|▏| 347/2000 [00:06<00:30, 53.34it/s, loss=0.178, test_loss=1.\n",
      "GBS - Fold 1:  79%|▊| 1579/2000 [00:31<00:08, 50.66it/s, loss=0.0059, test_loss=\n",
      "GBS - Fold 2:  16%|▏| 318/2000 [00:06<00:32, 51.60it/s, loss=0.205, test_loss=1.\n",
      "GBS - Fold 3:  15%|▏| 305/2000 [00:05<00:31, 53.29it/s, loss=0.225, test_loss=3.\n",
      "GBS - Fold 4: 100%|█| 2000/2000 [00:38<00:00, 52.60it/s, loss=0.0031, test_loss=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (GBS): 0.9237\n",
      "Mean Sensitivity (GBS): 0.5455\n",
      "Mean Specificity (GBS): 0.9626\n",
      "Mean AUC (GBS): 0.9339\n",
      "Working on JIA dataset: 302 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "JIA - Fold 0: 100%|█| 2000/2000 [00:42<00:00, 47.44it/s, loss=0.00331, test_loss\n",
      "JIA - Fold 1: 100%|█| 2000/2000 [00:42<00:00, 47.03it/s, loss=0.00414, test_loss\n",
      "JIA - Fold 2:  93%|▉| 1854/2000 [00:44<00:03, 41.96it/s, loss=0.00498, test_loss\n",
      "JIA - Fold 3:  91%|▉| 1820/2000 [00:42<00:04, 43.10it/s, loss=0.00452, test_loss\n",
      "JIA - Fold 4:  50%|▌| 1009/2000 [00:24<00:24, 41.11it/s, loss=0.0169, test_loss=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (JIA): 0.9901\n",
      "Mean Sensitivity (JIA): 0.9659\n",
      "Mean Specificity (JIA): 1.0000\n",
      "Mean AUC (JIA): 0.9985\n",
      "Working on Narcolepsy dataset: 263 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Narcolepsy - Fold 0:  17%|▏| 347/2000 [00:06<00:31, 51.79it/s, loss=0.152, test_\n",
      "Narcolepsy - Fold 1:  80%|▊| 1609/2000 [00:31<00:07, 51.74it/s, loss=0.00398, te\n",
      "Narcolepsy - Fold 2:  46%|▍| 913/2000 [00:17<00:21, 51.11it/s, loss=0.0182, test\n",
      "Narcolepsy - Fold 3:  88%|▉| 1770/2000 [00:34<00:04, 50.83it/s, loss=0.00337, te\n",
      "Narcolepsy - Fold 4:  92%|▉| 1842/2000 [00:36<00:03, 51.15it/s, loss=0.00361, te\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (Narcolepsy): 0.9924\n",
      "Mean Sensitivity (Narcolepsy): 0.9592\n",
      "Mean Specificity (Narcolepsy): 1.0000\n",
      "Mean AUC (Narcolepsy): 0.9933\n",
      "Working on RA dataset: 300 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "RA - Fold 0:  25%|▏| 491/2000 [00:10<00:31, 48.34it/s, loss=0.149, test_loss=1.2\n",
      "RA - Fold 1:  44%|▍| 870/2000 [00:18<00:23, 47.62it/s, loss=0.0555, test_loss=0.\n",
      "RA - Fold 2:  87%|▊| 1737/2000 [00:36<00:05, 47.09it/s, loss=0.0138, test_loss=0\n",
      "RA - Fold 3:  71%|▋| 1415/2000 [00:29<00:12, 47.90it/s, loss=0.0251, test_loss=0\n",
      "RA - Fold 4: 100%|█| 2000/2000 [00:42<00:00, 47.19it/s, loss=0.00893, test_loss=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (RA): 0.9067\n",
      "Mean Sensitivity (RA): 0.9535\n",
      "Mean Specificity (RA): 0.8879\n",
      "Mean AUC (RA): 0.9807\n",
      "Working on T1D dataset: 461 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "T1D - Fold 0:  76%|▊| 1514/2000 [00:57<00:18, 26.27it/s, loss=0.0217, test_loss=\n",
      "T1D - Fold 1:  61%|▌| 1228/2000 [00:46<00:29, 26.17it/s, loss=0.0362, test_loss=\n",
      "T1D - Fold 2:  72%|▋| 1443/2000 [00:55<00:21, 26.00it/s, loss=0.0301, test_loss=\n",
      "T1D - Fold 3:  60%|▌| 1204/2000 [00:45<00:30, 26.39it/s, loss=0.0309, test_loss=\n",
      "T1D - Fold 4:  48%|▍| 955/2000 [00:36<00:40, 25.86it/s, loss=0.0472, test_loss=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (T1D): 0.9328\n",
      "Mean Sensitivity (T1D): 0.9514\n",
      "Mean Specificity (T1D): 0.9112\n",
      "Mean AUC (T1D): 0.9864\n",
      "Working on MS dataset: 438 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "MS - Fold 0:  87%|▊| 1741/2000 [00:57<00:08, 30.24it/s, loss=0.0069, test_loss=0\n",
      "MS - Fold 1:  99%|▉| 1981/2000 [01:05<00:00, 30.33it/s, loss=0.00852, test_loss=\n",
      "MS - Fold 2: 100%|█| 2000/2000 [01:06<00:00, 30.21it/s, loss=0.00635, test_loss=\n",
      "MS - Fold 3:  57%|▌| 1144/2000 [00:37<00:27, 30.74it/s, loss=0.0215, test_loss=0\n",
      "MS - Fold 4:  54%|▌| 1082/2000 [00:35<00:30, 30.40it/s, loss=0.0294, test_loss=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (MS): 0.9726\n",
      "Mean Sensitivity (MS): 0.9866\n",
      "Mean Specificity (MS): 0.9579\n",
      "Mean AUC (MS): 0.9989\n",
      "Working on IAA dataset: 279 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "IAA - Fold 0:  68%|▋| 1365/2000 [00:30<00:14, 44.16it/s, loss=0.0127, test_loss=\n",
      "IAA - Fold 1:  62%|▌| 1248/2000 [00:29<00:17, 42.68it/s, loss=0.0137, test_loss=\n",
      "IAA - Fold 2:  82%|▊| 1631/2000 [00:37<00:08, 43.35it/s, loss=0.00773, test_loss\n",
      "IAA - Fold 3:  63%|▋| 1261/2000 [00:29<00:17, 43.45it/s, loss=0.00866, test_loss\n",
      "IAA - Fold 4:  61%|▌| 1226/2000 [00:27<00:17, 44.05it/s, loss=0.0128, test_loss=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (IAA): 0.9642\n",
      "Mean Sensitivity (IAA): 0.9231\n",
      "Mean Specificity (IAA): 0.9766\n",
      "Mean AUC (IAA): 0.9965\n",
      "Working on GBS dataset: 236 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "GBS - Fold 0:  18%|▏| 362/2000 [00:06<00:30, 53.04it/s, loss=0.162, test_loss=0.\n",
      "GBS - Fold 1: 100%|█| 2000/2000 [00:37<00:00, 53.04it/s, loss=0.00283, test_loss\n",
      "GBS - Fold 2:  17%|▏| 346/2000 [00:06<00:31, 52.91it/s, loss=0.17, test_loss=1.7\n",
      "GBS - Fold 3:  15%|▏| 307/2000 [00:05<00:32, 51.69it/s, loss=0.205, test_loss=3.\n",
      "GBS - Fold 4:  60%|▌| 1200/2000 [00:23<00:15, 51.68it/s, loss=0.00884, test_loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (GBS): 0.7373\n",
      "Mean Sensitivity (GBS): 0.9545\n",
      "Mean Specificity (GBS): 0.7150\n",
      "Mean AUC (GBS): 0.9091\n",
      "Working on JIA dataset: 302 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "JIA - Fold 0:  61%|▌| 1214/2000 [00:26<00:16, 46.37it/s, loss=0.0108, test_loss=\n",
      "JIA - Fold 1: 100%|█| 2000/2000 [00:42<00:00, 46.90it/s, loss=0.00438, test_loss\n",
      "JIA - Fold 2:  79%|▊| 1587/2000 [00:37<00:09, 42.60it/s, loss=0.00482, test_loss\n",
      "JIA - Fold 3: 100%|█| 2000/2000 [00:47<00:00, 42.13it/s, loss=0.00414, test_loss\n",
      "JIA - Fold 4: 100%|█| 2000/2000 [00:46<00:00, 42.85it/s, loss=0.00342, test_loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (JIA): 0.9801\n",
      "Mean Sensitivity (JIA): 0.9318\n",
      "Mean Specificity (JIA): 1.0000\n",
      "Mean AUC (JIA): 0.9992\n",
      "Working on Narcolepsy dataset: 263 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Narcolepsy - Fold 0: 100%|█| 2000/2000 [00:38<00:00, 51.79it/s, loss=0.00396, te\n",
      "Narcolepsy - Fold 1:  37%|▎| 740/2000 [00:14<00:24, 50.71it/s, loss=0.03, test_l\n",
      "Narcolepsy - Fold 2:  69%|▋| 1372/2000 [00:27<00:12, 50.00it/s, loss=0.00635, te\n",
      "Narcolepsy - Fold 3: 100%|█| 2000/2000 [00:39<00:00, 50.92it/s, loss=0.00277, te\n",
      "Narcolepsy - Fold 4:  58%|▌| 1161/2000 [00:22<00:16, 51.63it/s, loss=0.014, test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (Narcolepsy): 0.9582\n",
      "Mean Sensitivity (Narcolepsy): 0.9592\n",
      "Mean Specificity (Narcolepsy): 0.9579\n",
      "Mean AUC (Narcolepsy): 0.9958\n",
      "Working on RA dataset: 300 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "RA - Fold 0:  38%|▍| 750/2000 [00:16<00:26, 46.43it/s, loss=0.096, test_loss=0.2\n",
      "RA - Fold 1:  57%|▌| 1132/2000 [00:24<00:18, 47.00it/s, loss=0.0297, test_loss=0\n",
      "RA - Fold 2:  88%|▉| 1762/2000 [00:37<00:05, 46.70it/s, loss=0.00833, test_loss=\n",
      "RA - Fold 3:  51%|▌| 1029/2000 [00:21<00:20, 46.83it/s, loss=0.039, test_loss=0.\n",
      "RA - Fold 4:  26%|▎| 510/2000 [00:11<00:32, 46.24it/s, loss=0.19, test_loss=0.66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (RA): 0.9167\n",
      "Mean Sensitivity (RA): 0.8721\n",
      "Mean Specificity (RA): 0.9346\n",
      "Mean AUC (RA): 0.9701\n",
      "Working on T1D dataset: 461 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "T1D - Fold 0: 100%|█| 2000/2000 [01:15<00:00, 26.44it/s, loss=0.00889, test_loss\n",
      "T1D - Fold 1:  72%|▋| 1435/2000 [00:55<00:21, 26.07it/s, loss=0.0263, test_loss=\n",
      "T1D - Fold 2:  52%|▌| 1043/2000 [00:40<00:36, 25.95it/s, loss=0.0487, test_loss=\n",
      "T1D - Fold 3:  49%|▍| 979/2000 [00:37<00:39, 26.17it/s, loss=0.0441, test_loss=0\n",
      "T1D - Fold 4:  73%|▋| 1459/2000 [00:55<00:20, 26.23it/s, loss=0.0184, test_loss=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (T1D): 0.9284\n",
      "Mean Sensitivity (T1D): 0.9433\n",
      "Mean Specificity (T1D): 0.9112\n",
      "Mean AUC (T1D): 0.9900\n",
      "Working on MS dataset: 438 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark4090/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "MS - Fold 0:  76%|▊| 1513/2000 [00:49<00:16, 30.41it/s, loss=0.0104, test_loss=0\n",
      "MS - Fold 1: 100%|█| 2000/2000 [01:06<00:00, 30.03it/s, loss=0.00643, test_loss=\n",
      "MS - Fold 2:  67%|▋| 1341/2000 [00:44<00:22, 29.91it/s, loss=0.012, test_loss=0.\n",
      "MS - Fold 3:  86%|▊| 1730/2000 [00:57<00:08, 31.09it/s, loss=0.00801, test_loss="
     ]
    }
   ],
   "source": [
    "# Introduce an early stop mechanism\n",
    "sys.path.append('../')\n",
    "from python_codes.pytorchtools import EarlyStopping\n",
    "\n",
    "# Reading amino acid profile files\n",
    "aa_file = \"../AutoData214/PCA15.txt\"\n",
    "aa_vectors = get_features(aa_file)  \n",
    "\n",
    "# 5折交叉验证\n",
    "k_fold = 5\n",
    "kf = KFold(n_splits=k_fold, shuffle=True,random_state=42)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHES = 2000\n",
    "PATIENCE = 300\n",
    "\n",
    "all_accuracies = []  # 存储每一折的准确率\n",
    "all_sensitivities = []  # 存储每一折的灵敏度\n",
    "all_specificities = []  # 存储每一折的特异度\n",
    "all_aucs = []  # 存储每一折的AUC值\n",
    "\n",
    "device = \"cuda\"\n",
    "#disease_list = [\"RA\", \"T1D\", \"MS\", \"IAA\",\"GBS\",\"JIA\",\"NLSY\"]\n",
    "#disease_list = [\"BC\",\"BL\",\"BLCA\",\"BreastC\",\"CC\",\"COLOC\",\"DLBCL\",\"GBM\",\"HCC\",\"ILAC\",\"KS\",\"LUAD\",\"LungC\",\"MCC\",\"Melanoma\",\"MF\",\"NSCLC\",\"OSTCA\",\"OV\",\"PADD\",\"PCA\",\"RCC\",\"SCLC\"]\n",
    "disease_list = [\"RA\", \"T1D\", \"MS\", \"IAA\",\"GBS\",\"JIA\",\"Narcolepsy\"]\n",
    "# 在这里设置存储结果的目录路径\n",
    "results_dir = \"../AutoTFCNN5Y_Results_100\"\n",
    "os.makedirs(results_dir, exist_ok=True)  # 如果目录不存在，则创建它\n",
    "\n",
    "# 在这里设置存储 CSV 文件的目录路径\n",
    "csv_results_dir = \"../AutoTFCNN5Y_CSV_Results_100\"\n",
    "os.makedirs(csv_results_dir, exist_ok=True)  # 如果目录不存在，则创建它\n",
    "\n",
    "\n",
    "for iteration  in range(100):  # 循环100次\n",
    "    results = []\n",
    "    results_ROC = []\n",
    "    \n",
    "    ################################\n",
    "    results_ROC_CI = []\n",
    "    #################################\n",
    "    \n",
    "    \n",
    "    for disease_name in disease_list:\n",
    "        data_dir = f'../AutoData214/{disease_name}'\n",
    "        training_data, training_labels = load_data(data_dir)\n",
    "        print(f\"Working on {disease_name} dataset: {len(training_data)} samples\")\n",
    "\n",
    "\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "\n",
    "        # 分成5折\n",
    "        for fold, (train_idx, test_idx) in enumerate(kf.split(training_data)):\n",
    "            train_data = [training_data[i] for i in train_idx]\n",
    "            train_labels = [training_labels[i] for i in train_idx]\n",
    "            test_data = [training_data[i] for i in test_idx]\n",
    "            test_labels = [training_labels[i] for i in test_idx]\n",
    "\n",
    "\n",
    "            # After the training and test sets are fixed, the training set is then divided into a training set and a validation set\n",
    "            train_data, valid_data, train_labels, valid_labels = train_test_split(train_data, train_labels, test_size=0.2, random_state=1234)\n",
    "\n",
    "\n",
    "            train_input_batch, train_label_batch = generate_input(train_data, train_labels, aa_vectors, 15, 100, 24)\n",
    "\n",
    "            train_input_batch, train_label_batch = torch.Tensor(train_input_batch).to(torch.device(\"cuda\")), torch.LongTensor(train_label_batch).to(torch.device(\"cuda\"))\n",
    "\n",
    "            valid_input_batch, valid_label_batch = generate_input(valid_data, valid_labels, aa_vectors, 15, 100, 24)\n",
    "            valid_input_batch, valid_label_batch = torch.Tensor(valid_input_batch).to(torch.device(\"cuda\")), torch.LongTensor(valid_label_batch).to(torch.device(\"cuda\"))\n",
    "\n",
    "            test_input_batch, test_label_batch = generate_input(test_data, test_labels, aa_vectors, 15, 100, 24)\n",
    "            test_input_batch, test_label_batch = torch.Tensor(test_input_batch).to(torch.device(\"cuda\")), torch.LongTensor(test_label_batch).to(torch.device(\"cuda\"))\n",
    "\n",
    "\n",
    "            # 在数据加载部分，确保标签是浮点数\n",
    "            train_label_batch = train_label_batch.float()\n",
    "            valid_label_batch = valid_label_batch.float()\n",
    "            test_label_batch = test_label_batch.float()\n",
    "\n",
    "            train_dataset = Data.TensorDataset(train_input_batch, train_label_batch)\n",
    "            valid_dataset = Data.TensorDataset(valid_input_batch, valid_label_batch)\n",
    "            test_dataset = Data.TensorDataset(test_input_batch, test_label_batch)\n",
    "\n",
    "            train_loader = Data.DataLoader(train_dataset, len(train_input_batch), True)\n",
    "            valid_loader = Data.DataLoader(valid_dataset, len(valid_input_batch), True)\n",
    "            test_loader = Data.DataLoader(test_dataset, len(test_input_batch), True)\n",
    "\n",
    "\n",
    "            model = init_model().to(device)\n",
    "            criterion = nn.BCEWithLogitsLoss()  # 使用BCEWithLogitsLoss\n",
    "            optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "            train(fold, model, criterion, optimizer, train_loader, valid_loader, epoches=NUM_EPOCHES, device=device)\n",
    "\n",
    "            # 在测试集上进行最终评估\n",
    "            _, preds, labels = evaluate(model, criterion, test_loader, device=device)\n",
    "            all_preds += preds\n",
    "            all_labels += labels\n",
    "\n",
    "        all_preds = np.concatenate(all_preds, axis=0)\n",
    "        all_labels = np.concatenate(all_labels, axis=0)\n",
    "        \n",
    "        accuracy, sensitivity, specificity, auc = metrics(all_preds, all_labels)\n",
    "        print(f\"Mean Accuracy ({disease_name}): {accuracy:.4f}\")\n",
    "        print(f\"Mean Sensitivity ({disease_name}): {sensitivity:.4f}\")\n",
    "        print(f\"Mean Specificity ({disease_name}): {specificity:.4f}\")\n",
    "        print(f\"Mean AUC ({disease_name}): {auc:.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            'disease': disease_name,\n",
    "            'accuracy': accuracy,\n",
    "            'sensitivity': sensitivity,\n",
    "            'specificity': specificity,\n",
    "            'auc': auc\n",
    "        })\n",
    "\n",
    "        results_ROC.append({\n",
    "            'disease': disease_name,\n",
    "            'auc': auc,\n",
    "            'all_preds': all_preds,\n",
    "            'all_labels': all_labels\n",
    "        })\n",
    "        \n",
    "        all_probs = sigmoid(np.array(all_preds))\n",
    "        ################################\n",
    "        results_ROC_CI += [(disease_name, iteration, z[0], z[1]) for z in zip(all_probs, all_labels)]\n",
    "        ################################\n",
    "        \n",
    "        \n",
    "    # 在处理所有疾病后，将本次循环的结果保存到 TSV 文件中\n",
    "    results_filename = f\"results_{iteration+1}.tsv\"\n",
    "    results_ROC_filename = f\"results_ROC_{iteration+1}.tsv\"\n",
    "    results_filepath = os.path.join(results_dir, results_filename)\n",
    "    results_ROC_filepath = os.path.join(results_dir, results_ROC_filename)\n",
    "    \n",
    "    ################################  \n",
    "    # 定义CSV文件的名称和路径\n",
    "    csv_filename = f'CI{iteration}.csv'\n",
    "    csv_filepath = os.path.join(csv_results_dir, csv_filename)\n",
    "    # 保存 results_ROC_CI 到 CSV 文件\n",
    "    pd.DataFrame(results_ROC_CI, columns=['Disease', 'Iteration', 'Pred', 'Label']).to_csv(csv_filepath, index=False)\n",
    "    ################################\n",
    "\n",
    "    # 保存 results 到 TSV\n",
    "    with open(results_filepath, 'w') as file:\n",
    "        for result in results:\n",
    "            line = \"\\t\".join([str(result[key]) for key in result])\n",
    "            file.write(line + \"\\n\")\n",
    "\n",
    "    # 保存 results_ROC 到 TSV\n",
    "    with open(results_ROC_filepath, 'w') as file:\n",
    "        for result in results_ROC:\n",
    "            line = \"\\t\".join([str(result[key]) if key != 'all_preds' and key != 'all_labels' else ','.join(map(str, result[key])) for key in result])\n",
    "            file.write(line + \"\\n\")\n",
    "    \n",
    "    # 将本次循环的性能指标值添加到列表中\n",
    "    all_accuracies.append([result['accuracy'] for result in results])\n",
    "    all_sensitivities.append([result['sensitivity'] for result in results])\n",
    "    all_specificities.append([result['specificity'] for result in results])\n",
    "    all_aucs.append([result['auc'] for result in results])\n",
    "\n",
    "    \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd01322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算性能指标的均值和标准差\n",
    "mean_accuracy = np.mean(all_accuracies, axis=0)\n",
    "mean_sensitivity = np.mean(all_sensitivities, axis=0)\n",
    "mean_specificity = np.mean(all_specificities, axis=0)\n",
    "mean_auc = np.mean(all_aucs, axis=0)\n",
    "\n",
    "Statistics_accuracy = np.std(all_accuracies, axis=0)\n",
    "Statistics_sensitivity = np.std(all_sensitivities, axis=0)\n",
    "Statistics_specificity = np.std(all_specificities, axis=0)\n",
    "Statistics_auc = np.std(all_aucs, axis=0)\n",
    "\n",
    "# 打印均值和标准差\n",
    "for idx, disease_name in enumerate(disease_list):\n",
    "    print(f\"Mean Accuracy ({disease_name}): {mean_accuracy[idx]:.4f}, Statistics: {Statistics_accuracy[idx]:.4f}\")\n",
    "    print(f\"Mean Sensitivity ({disease_name}): {mean_sensitivity[idx]:.4f}, Statistics: {Statistics_sensitivity[idx]:.4f}\")\n",
    "    print(f\"Mean Specificity ({disease_name}): {mean_specificity[idx]:.4f}, Statistics: {Statistics_specificity[idx]:.4f}\")\n",
    "    print(f\"Mean AUC ({disease_name}): {mean_auc[idx]:.4f}, Statistics: {Statistics_auc[idx]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef665f96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f966fa7-6361-4220-b9ca-0f83d4377478",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
