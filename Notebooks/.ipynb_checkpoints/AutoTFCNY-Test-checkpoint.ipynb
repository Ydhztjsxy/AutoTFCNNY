{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dbcece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve, auc, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define functions to read TSV files\n",
    "def read_tsv(filename, inf_ind, skip_1st=False, file_encoding=\"utf8\"):\n",
    "    extract_inf = []\n",
    "    with open(filename, \"r\", encoding=file_encoding) as tsv_f:\n",
    "        if skip_1st:\n",
    "            tsv_f.readline()\n",
    "        line = tsv_f.readline()\n",
    "        while line:\n",
    "            line_list = line.strip().split(\"\\t\")\n",
    "            temp_inf = [line_list[ind] for ind in inf_ind]\n",
    "            extract_inf.append(temp_inf)\n",
    "            line = tsv_f.readline()\n",
    "    return extract_inf\n",
    "\n",
    "# Define a function that reads an amino acid feature file and generates a feature dictionary\n",
    "def get_features(filename, f_num=15):\n",
    "    f_list = read_tsv(filename, list(range(16)), True)\n",
    "    f_dict = {}\n",
    "    left_num = 0\n",
    "    right_num = 0\n",
    "    if f_num > 15:\n",
    "        left_num = (f_num - 15) // 2\n",
    "        right_num = f_num - 15 - left_num\n",
    "    for f in f_list:\n",
    "        f_dict[f[0]] = [0] * left_num + [float(x) for x in f[1:]] + [0] * right_num\n",
    "    f_dict[\"X\"] = [0] * f_num\n",
    "    return f_dict\n",
    "\n",
    "# Defining Input Functions\n",
    "def generate_input(sps, sp_lbs, feature_dict, feature_num, ins_num, max_len):\n",
    "    xs, ys = [], []\n",
    "    i = 0\n",
    "    for sp in sps:\n",
    "        xs.append([[[0] * feature_num] * max_len] * ins_num)\n",
    "        ys.append(sp_lbs[i])\n",
    "        j = 0\n",
    "        for tcr in sp:\n",
    "            tcr_seq = tcr[0]\n",
    "            right_num = max_len - len(tcr_seq)\n",
    "            tcr_seq += \"X\" * right_num\n",
    "            tcr_matrix = []\n",
    "            for aa in tcr_seq:\n",
    "                tcr_matrix.append(feature_dict[aa.upper()])\n",
    "            xs[i][j] = tcr_matrix\n",
    "            j += 1\n",
    "        i += 1\n",
    "    xs = np.array(xs)\n",
    "    xs = xs.swapaxes(2, 3)\n",
    "    ys = np.array(ys)\n",
    "    return xs, ys\n",
    "\n",
    "\n",
    "#Define the Generate Label function\n",
    "def load_data(sample_dir):\n",
    "    training_data = []\n",
    "    training_labels = []\n",
    "    for sample_file in os.listdir(sample_dir):\n",
    "        training_data.append(read_tsv(os.path.join(sample_dir, sample_file), [0, 1], True))\n",
    "        if \"P\" in sample_file:\n",
    "            training_labels.append(1)\n",
    "        elif \"H\" in sample_file:\n",
    "            training_labels.append(0)\n",
    "        else:\n",
    "            print(\"Wrong sample filename! Please name positive samples with 'P' and negative samples with 'H'.\")\n",
    "            sys.exit(1)\n",
    "        \n",
    "    return training_data, training_labels\n",
    "\n",
    "  \n",
    "\n",
    "#Define the evaluation function\n",
    "def evaluate(model, criterion, test_loader, device=\"cuda\"):\n",
    "    test_total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for test_batch_x, test_batch_y in test_loader:\n",
    "            test_batch_x = test_batch_x.to(device)\n",
    "            test_batch_y = test_batch_y.to(device).view(-1, 1)  \n",
    "            test_pred = model(test_batch_x)\n",
    "\n",
    "            test_loss = criterion(test_pred, test_batch_y)\n",
    "            test_total_loss += test_loss.item()\n",
    "            all_preds.append(test_pred.cpu().numpy())\n",
    "            all_labels.append(test_batch_y.cpu().numpy())\n",
    "            \n",
    "        test_avg_loss = test_total_loss / len(test_loader)\n",
    "        return test_avg_loss, all_preds, all_labels\n",
    "\n",
    "    \n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))     \n",
    "\n",
    "# Define a function to compute a binary classification indicator               \n",
    "def metrics(all_preds, all_labels, threshold):\n",
    "   \n",
    "    all_probs = sigmoid(np.array(all_preds))\n",
    "  \n",
    "    binary_preds = (all_probs > threshold).astype(int)\n",
    "    conf_matrix = confusion_matrix(all_labels, binary_preds)\n",
    "    accuracy = accuracy_score(all_labels, binary_preds)\n",
    "    sensitivity = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "    specificity = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    auc = roc_auc_score(all_labels, all_probs)\n",
    "    \n",
    "    return accuracy, sensitivity, specificity, auc        \n",
    "\n",
    "\n",
    "#Define CNNLayer                \n",
    "class CNNLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        super(CNNLayer, self).__init__()\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.bn = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.adaptive_maxpool = nn.AdaptiveMaxPool1d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.adaptive_maxpool(x)\n",
    "        return x\n",
    "    \n",
    "#Define PositionalEncoding\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.3, max_len=100):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        \n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "      \n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        \n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        \n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "       \n",
    "#Define AutoTFCNNY    \n",
    "class AutoTFCNNY(nn.Module):\n",
    "    def __init__(self, feature_num, hidden_size, output_size, num_heads, num_layers, dropout, max_len, ins_num):\n",
    "        super(AutoTFCNNY, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size  \n",
    "        self.ins_num = ins_num\n",
    "\n",
    "        self.input_embedding = nn.Linear(feature_num, hidden_size)\n",
    "        \n",
    "        self.pos_encoder = PositionalEncoding(hidden_size, dropout, max_len)\n",
    "\n",
    "        \n",
    "        self.cnn1 = CNNLayer(hidden_size, hidden_size, kernel_size=8, stride=1, padding=4)\n",
    "        \n",
    "        self.batchnorm1 = nn.BatchNorm1d(hidden_size)  \n",
    "\n",
    "        self.encoder_layers = nn.TransformerEncoderLayer(d_model=hidden_size, nhead=num_heads, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layers, num_layers=num_layers)\n",
    "\n",
    "        \n",
    "        self.cnn2 = CNNLayer(hidden_size, hidden_size, kernel_size=8, stride=1, padding=4)\n",
    "        \n",
    "        self.batchnorm2 = nn.BatchNorm1d(hidden_size)  \n",
    "        self.dropout = nn.Dropout(p=dropout)  \n",
    "\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.input_embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = src.flatten(0, 1)\n",
    "        src = src.permute(2, 0, 1)\n",
    "        src = self.input_embedding(src)\n",
    "        src = self.pos_encoder(src)\n",
    "\n",
    "        \n",
    "        src = src.permute(1, 2, 0) \n",
    "        src = self.cnn1(src)\n",
    "        src = self.batchnorm1(src)  \n",
    "        src = src.permute(2, 0, 1)  \n",
    "\n",
    "        output = self.transformer_encoder(src)\n",
    "\n",
    "        \n",
    "        output = output.permute(1, 2, 0)\n",
    "        output = self.cnn2(output)\n",
    "        output = self.batchnorm2(output)  \n",
    "        output = output.permute(2, 0, 1)\n",
    "\n",
    "        output = output[0]\n",
    "        output = output.view(-1, self.ins_num, self.hidden_size)\n",
    "\n",
    "        \n",
    "        output = self.dropout(output)\n",
    "\n",
    "        output = output.mean(dim=1)\n",
    "        output = self.decoder(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "# Setting model parameters     \n",
    "def init_model():\n",
    "    \n",
    "    feature_num = 15  \n",
    "    hidden_size = 30  \n",
    "    output_size = 1  \n",
    "    num_heads = 6  \n",
    "    num_layers = 2  \n",
    "    dropout = 0.6  \n",
    "    max_len = 24  \n",
    "    ins_num = 100  \n",
    "\n",
    "    model = AutoTFCNNY(feature_num, hidden_size, output_size, num_heads, num_layers, dropout, max_len, ins_num)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8baee58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Test Functions\n",
    "def process_Cancer(model_name, Cancers_name):\n",
    "    # Reading model files\n",
    "    model_path = f'../Model Test Files/{model_name}checkpoint.pth'\n",
    "    # New Test Set Path\n",
    "    new_data_dir = f'../New Test Data/{Cancers_name}/'\n",
    "    # Read the amino acid characterization file\n",
    "    aa_file = \"../Data/PCA15.txt\"\n",
    "    aa_vectors = get_features(aa_file) \n",
    "    \n",
    "    \n",
    "    device=\"cuda\"\n",
    "\n",
    "    model = init_model().to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    \n",
    "    new_data, new_labels = load_data(new_data_dir)  \n",
    "\n",
    "   \n",
    "    new_input_batch, new_label_batch = generate_input(new_data, new_labels, aa_vectors, 15, 100, 24)\n",
    "\n",
    "\n",
    "    new_input_batch, new_label_batch = torch.Tensor(new_input_batch).to(torch.device(\"cuda\")), torch.LongTensor(new_label_batch).to(torch.device(\"cuda\"))\n",
    "\n",
    "\n",
    "    new_label_batch = new_label_batch.float()\n",
    "\n",
    "   \n",
    "    new_dataset = torch.utils.data.TensorDataset(new_input_batch, new_label_batch)\n",
    "\n",
    "    new_loader = torch.utils.data.DataLoader(new_dataset, batch_size=len(new_input_batch), shuffle=False)\n",
    "\n",
    "  \n",
    "    _, new_preds, new_labels = evaluate(model, criterion, new_loader, device=device)\n",
    "    new_preds = np.concatenate(new_preds, axis=0)\n",
    "    new_labels = np.concatenate(new_labels, axis=0)\n",
    "    all_probs = sigmoid(np.array(new_preds))\n",
    "    \n",
    "    return new_labels,all_probs,new_preds\n",
    "\n",
    "\n",
    "Cancers = [\"UBC\",\"BRCA\",\"NSCLC\",\"Melanoma\",\"CRC\"]     # Cancer \n",
    "model_names = [\"UBC\",\"BRCA\",\"NSCLC\",\"Melanoma\",\"CRC\"]  # Cancer\n",
    "\n",
    "performance_results = []  \n",
    "\n",
    "for Cancer, model_name in zip(Cancers, model_names):\n",
    "    new_labels, _,new_preds = process_Cancer(model_name, Cancer) \n",
    "    \n",
    "    \n",
    "    accuracy, sensitivity, specificity, auc_score = metrics(new_preds, new_labels, 0.5)\n",
    "    \n",
    "    \n",
    "    performance_results.append({\n",
    "        'Cancer': Cancer,\n",
    "        'Accuracy': accuracy,\n",
    "        'Sensitivity': sensitivity,\n",
    "        'Specificity': specificity,\n",
    "        'AUC': auc_score\n",
    "    })\n",
    "    \n",
    "    \n",
    "    print(f\"{Cancer} - Accuracy: {accuracy:.4f}, Sensitivity: {sensitivity:.4f}, Specificity: {specificity:.4f}, AUC: {auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e41dd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting ROC graphs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the number of subplots\n",
    "num_plots = len(Cancers)\n",
    "num_rows = (num_plots + 1) // 2\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, 2, figsize=(18, 6*num_rows))\n",
    "subplot_labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g']  # Add more labels if needed\n",
    "\n",
    "if num_rows == 1:\n",
    "    axes = axes.flatten()\n",
    "\n",
    "# Iterate over the subplots and plot the ROC curves\n",
    "for i, (Cancer, model_name) in enumerate(zip(Cancers, model_names)):\n",
    "    row_idx = i // 2\n",
    "    col_idx = i % 2\n",
    "    \n",
    "    labels, probs, _ = process_Cancer(model_name, Cancer)\n",
    "    fpr, tpr, _ = roc_curve(labels, probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    \n",
    "    axes[row_idx, col_idx].plot(1 - fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.4f}')\n",
    "    axes[row_idx, col_idx].plot([1, 0], [0, 1], '--', color='grey')\n",
    "    axes[row_idx, col_idx].set_xlim([1.0, 0.0])\n",
    "    axes[row_idx, col_idx].set_ylim([0.0, 1.05])\n",
    "    axes[row_idx, col_idx].set_xlabel('Specificity')\n",
    "    axes[row_idx, col_idx].set_ylabel('Sensitivity')\n",
    "    axes[row_idx, col_idx].set_title(f'{Cancer}')\n",
    "    axes[row_idx, col_idx].legend(loc=\"lower right\")\n",
    "    axes[row_idx, col_idx].text(-0.1, 1.05, subplot_labels[i], transform=axes[row_idx, col_idx].transAxes, fontsize=16, fontweight='bold', va='top', ha='right')\n",
    "\n",
    "# Hide any unused subplots\n",
    "for i in range(num_plots, num_rows * 2):\n",
    "    row_idx = i // 2\n",
    "    col_idx = i % 2\n",
    "    axes[row_idx, col_idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "#save_path = \"../Result/Test-roc.png\"\n",
    "#plt.savefig(save_path, dpi=300)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
